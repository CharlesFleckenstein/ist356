# IST356: Programming Techniques for Data Analytics

## Course Description
The exploration of common approaches for building data pipelines used in analytics. Emphasis on both exploratory and production scenarios. Programming experience required.

### Additional Course Description

This course is a tour of programming techniques for building data pipelines for analytics. It will not just emphasize exploratory approaches, but also techniques to build extract transform load pipelines to run code in production. 
Throughout the course we will learn how to source data from a variety of sources (files, data streams, APIs, web scraping, etc.) and ultimately transform data as to prepare it for dashboards or machine learning. 

### Prerequisites

 This courses uses the Python programming language. Proficiency n any programming language is the only pre-requisite. Students should have a clear understanding of these concepts: 

 - Input, output, variables and data types
 - Control flow statements (if, for, while)
 - Functions (function definition, calling, parameters, return values)
 - Data structures (lists, dictionaries)
 - Using code in other libraries 

Not sure if you should take this course? Try the readiness exam: [TODO: Link to readiness exam]


### Audience

This course is intended as a follow up course to IST256. It is also appropriate for students with a background in programming and an interest in data analytics.

### Credits

3 credits

### Course Fees

None

## Learning Objectives

Upon completion of this course, students will be able to:

1. Explain techniques for sourcing or transforming data, and be able to justify the choice of technique
2. Solve data-oriented problems using programming techniques
3. Evaluate different code modules and application programming interfaces for suitability
4. Apply data transformational programming techniques to build a larger data pipelines
5. Create production quality data pipelines from exploratory code


## Textbooks And Supplies

### Textbooks

- [Python for Data Analysis](https://wesmckinney.com/book/) by Wes McKinney
- [Data Engineering Cookbook](https://cookbook.learndataengineering.com/) by Daniel Rodriguez
- [Web Scraping with Python](https://www.oreilly.com/library/view/web-scraping-with/9781491985564/) by Ryan Mitchell

### Bring Your Own Device

This course is bring your own device. You will need a Windows, Mac, or Chromebook for this course and be expected to install software on your own computer. You are expected to bring the device to class each day.

[TODO: link to software installation instructions / or script to install software]

## Course Requirements and Expectations

### Attendance and Participation

You are expected to attend and participate in every class session. If you must miss class, you are responsible for making up the work and catching up on what you missed. Do expect a pre-recorded lecture or instructor support if you miss class. A suggestion is to partner with a classmate to share notes from class.

### Assignments

Each topics will have a lab assignment. [TODO: explain assignments and grading]

### Exams

There will be two exams in the course. Both exams are experiential. You will be expected to build an exploratory data pipeline with code as part of the examination. 
[TODO: get specific about the exams]

### Project

In your final project you will be expected to create a data pipeline of your choosing. 

- The pipeline should incorporate techniques we learned in the course and the more techniques you incorporate correctly the higher your grade.
- It is expected that you will be able to explain your choices, and they will be appropriate for the problem.
- The pipeline should be first written exploratory, and then refactored into a production quality pipeline. Both pipelines should be submitted.
- There should be a simple data visualization or dashboard from the pipeline output as to demonstrate its usefulness.

[TODO: get specific about the project]


## Grading

| Assessment | Type | Learning Outcomes | Quantity | Points Each | Points Total |
|------------|------|-------------------|----------|-------------|--------------|
| Lab Assignments | Formative | 1, 2 | 10 | 2 | 30 |
| Exams | Summative | 3, 4 | 2 | 20 | 40 |
| Project | Summative | 5 | 1 | 30 | 30 |
| **Total** | | | | | **100** |

### Grading Table

The following grading scale translates your total points earned into a letter grade to be submitted to the University registrar.

| Student Achievement | Total Points Earned	| Registrar Grade |Grade Points |
|---------------------|---------------------|-----------------|-------------|
| Mastery | 475 - 500 | A | 4.000 |
| | 450 - 474 | A- | 3.666 |
| Satisfactory | 425 - 449 | B+ | 3.333 |
| | 400 - 424   | B | 3.000 |
| | 375 - 399  | B- | 2.666 |
| Low Passing  | 350 - 374 | C+ | 2.333 |
| | 325 - 349  | C | 2.000 |
| | 300 - 324  | C- | 1.666 |
| Unsatisfactory | 250 - 299  | D | 1.000 |
| | 0 - 249 | F | 0.000 |


## Schedule Of Topics

ROUGH DRAFT: ORDER OF TOPICS MAY CHANGE AND I WILL KNOW MORE WHEN I BUILD OUT LABS

| Week | Topic | Reading | Assignment |
|------|-------|---------|------------|
| 1 | Programming in Python | McKinney Ch,1,2,3 | Lab 1 |
| 2 | Pip, Modules, Ipython interact | TODO | Lab 2 |
| 3 | HTTP, REST, API's| TODO | Lab 3 |
| 4 | More API's, OAUTH2 |TODO | Lab 4 |
| 5 | Pandas and Numpy basics series, and indexes| McKinney 4,5,6 | Lab 5 |
| 6 | Pandas: joins, append, Combine, lambdas | McKinney 7,8,9  | Lab 6 |
| 7 | Pandas: timeseries, aggregation, date handling  | McKinney 10,11| Lab 7 |
| 8 | Web Scraping: HTML, and Beautiful Soup | Mitchell 1,2,3 | Lab 8 |
| 9 | Web Scraping: Javascript and Form submission | Mitchell 4,10,11 | Lab 9 |
| 10 | Web Driving with Selenium  |TODO | Lab 10 |
| 11 | Plotting and Mapping | TODO | Lab 11 |
| 12 | Production: Logging, Deploying cloud; preparing code for production. | Kretz | Lab 10 |
| 13 | Cloud and Object Storage  |TODO | Lab 10 |
| 14 | Placeholder for another topic  |TODO | Lab 10 |

